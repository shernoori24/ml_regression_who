# -*- coding: utf-8 -*-
"""coved19_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14uHMWVHNSC_ldXjbqrIN_pRrELUmJw2G
"""

import pandas as pd
import numpy as np

df = pd.read_csv('full_clean_covid_19.csv')
print(df.info())

#df = df.drop(columns=['new_cases', 'new_deaths', 'total_recovered', 'active_cases'])

df_simple = df.sample(n=5000, random_state=42)
print(df_simple.info())

#tuax de mortalité dans une nouvelle colomn
df_simple['mortality_rate'] = df_simple['total_deaths'] / df_simple['total_cases']
#en percentage
df_simple['mortality_rate'] = df_simple['mortality_rate'] * 100
# show 5 primier lines
df_simple.head()


#retitrer les deux colonnes 'totale_death' et 'totale_case'
df_simple = df_simple.drop(columns=['total_deaths', 'total_cases'])

df_simple.head()

# Assurez-vous que la colonne observation_date est en format datetime
df_simple['observation_date'] = pd.to_datetime(df_simple['observation_date'])
print(df_simple.head())

print(df_simple.isnull().sum())

mois_francais = {
    1: 'Janvier', 2: 'Février', 3: 'Mars', 4: 'Avril',
    5: 'Mai', 6: 'Juin', 7: 'Juillet', 8: 'Août',
    9: 'Septembre', 10: 'Octobre', 11: 'Novembre', 12: 'Décembre'
}

df_simple['mois'] = df_simple['observation_date'].dt.month.map(mois_francais)
df_simple.head()

def obtenir_saison(mois):
    """
    Définit les saisons selon l'hémisphère nord:
    Hiver: Décembre, Janvier, Février
    Printemps: Mars, Avril, Mai
    Été: Juin, Juillet, Août
    Automne: Septembre, Octobre, Novembre
    """
    if mois in [12, 1, 2]:
        return 'Hiver'
    elif mois in [3, 4, 5]:
        return 'Printemps'
    elif mois in [6, 7, 8]:
        return 'Été'
    else:  # 9, 10, 11
        return 'Automne'

df_simple['saison'] = df_simple['observation_date'].dt.month.apply(obtenir_saison)
df_simple.head()

import matplotlib.pyplot as plt
df_simple['new_cases'].hist(bins=30)
plt.title('new_cases')
plt.xlabel('amout_of_new cases')
plt.ylabel('repeated_cases')
plt.show()

df_simple['new_cases'] = df_simple['new_cases'].fillna(df_simple['new_cases'].median())
df_simple.info()

# delete colon abservation_date
df_simple = df_simple.drop(columns=['observation_date'])

#  passer tous les string en dummy
df_simple = pd.get_dummies(df_simple, drop_first=True)
df_simple.head()
#colonnes_categorique = ['country', 'province_state', 'city']  # exemple
#df_simple = pd.get_dummies(df_simple, columns=colonnes_categorique, drop_first=True)

from sklearn.preprocessing import StandardScaler

# 1. Définir la variable cible
# Y = df_simple['new_cases']

# 2. Identifier toutes les colonnes numériques (int and float)
colonnes_numeriques = df_simple.select_dtypes(include=np.number).columns.tolist()

# 3. Retirer la variable cible de la liste
colonnes_numeriques_sans_Y = [col for col in colonnes_numeriques if col != 'mortality_rate']

# 4. Appliquer le scaler uniquement sur ces colonnes
scaler = StandardScaler()
df_simple[colonnes_numeriques_sans_Y] = scaler.fit_transform(df_simple[colonnes_numeriques_sans_Y])

import numpy as np

# Vérifier les NaN
print(df_simple[colonnes_numeriques_sans_Y].isna().sum())

print("-"*20)

# Vérifier les infinis
print(np.isinf(df_simple[colonnes_numeriques_sans_Y]).sum())

# Remplacer les infinis par NaN
df_simple[colonnes_numeriques_sans_Y] = df_simple[colonnes_numeriques_sans_Y].replace([np.inf, -np.inf], np.nan)

# Imputer les NaN par la médiane (plus robuste)
df_simple[colonnes_numeriques_sans_Y] = df_simple[colonnes_numeriques_sans_Y].fillna(df_simple[colonnes_numeriques_sans_Y].median())

scaler = StandardScaler()
df_simple[colonnes_numeriques_sans_Y] = scaler.fit_transform(df_simple[colonnes_numeriques_sans_Y])

df_simple.head()

#convertire les colonn true false en 1 0
df_simple = df_simple.astype({col: int for col in df_simple.select_dtypes('bool').columns})
df_simple.head()

#supprimer les colon constant
df_simple = df_simple.loc[:, df_simple.nunique() > 1]

"""Définir X et Y"""

# Y = variable cible : taux de mortalité
Y = df_simple['mortality_rate']

# X = toutes les autres variables explicatives
X = df_simple.drop(columns=['mortality_rate'])

"""Séparer les données (80/20 avec shuffle)"""

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.2, shuffle=True, random_state=42
)

"""Initialiser et ajuster le modèle de régression linéaire"""

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, Y_train)

"""Extraire les coefficients (bêta)"""

import pandas as pd

coefficients = pd.DataFrame({
    'Variable': X.columns,
    'Coefficient (β)': model.coef_
}).sort_values(by='Coefficient (β)', key=abs, ascending=False)

print(coefficients.head(15))  # Les 15 variables les plus influentes

"""Évaluer le modèle avec R²"""

from sklearn.metrics import r2_score

Y_pred = model.predict(X_test)
r2 = r2_score(Y_test, Y_pred)

print(f"Score R² : {r2:.4f}")

"""Visualiser"""

import matplotlib.pyplot as plt

plt.scatter(Y_test, Y_pred)
plt.xlabel("Valeurs réelles")
plt.ylabel("Prédictions")
plt.title("Prédictions vs Réel")
plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], color='red')
plt.show()